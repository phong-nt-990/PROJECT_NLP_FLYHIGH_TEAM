# ƒê·ªí √ÅN M√îN H·ªåC - X·ª¨ L√ç NG√îN NG·ªÆ T·ª∞ NHI√äN

# ***TH√îNG TIN ƒê·ªí √ÅN:***

- T√™n ƒë·ªì √°n: X·ª≠ l√≠ ng√¥n ng·ªØ t·ª± nhi√™n (Natural Language Processing) - NLP
- L·ªõp: Tr√≠ tu·ªá nh√¢n t·∫°o - 21TNT1
- Tr∆∞·ªùng: ƒê·∫°i h·ªçc Khoa h·ªçc t·ª± nhi√™n - ƒêHQG TPHCM (HCMUS)
- M√¥n: Gi·ªõi thi·ªáu tr√≠ tu·ªá nh√¢n t·∫°o - CSC00006
- H·ªç v√† t√™n ng∆∞·ªùi tham gia ƒë·ªì √°n:
    - Tr·∫ßn Ng·ªçc B·∫£o (Nh√≥m tr∆∞·ªüng)
    - Nguy·ªÖn Anh Kh√¥i
    - Nguy·ªÖn Ch√≠ C∆∞·ªùng
    - Nguy·ªÖn VƒÉn Tr√≠
    - Nguy·ªÖn Th·∫ø Phong

# *N·ªòI DUNG ƒê·ªí √ÅN - M·ª§C TI√äU C·ª¶A PH·∫¶N M·ªÄM*

- L√† ·ª©ng d·ª•ng t√¨m ki·∫øm c∆° b·∫£n
- C√°ch th·ª©c ho·∫°t ƒë·ªông: OCR ‚Üí NLP ‚Üí Search

# *C√ÅCH TH·ª®C TRI·ªÇN KHAI - M√É NGU·ªíN PH·∫¶N M·ªÄM*

## 1. OCR

1. Th√¥ng tin
    - App: VietOCR.
    - ƒê·ªô ch√≠nh x√°c r·∫•t cao: 90% ‚Üí 95%
    - C√°c ch·ª©c nƒÉng: OCR h√¨nh ·∫£nh sang file txt, c√≥ ch·ª©c nƒÉng chuy·ªÉn nhi·ªÅu file c√πng 1 l√∫c.
    - H·ªó tr·ª£ ƒë·ªìng th·ªùi ti·∫øng Anh v√† ti·∫øng Vi·ªát
2. C√°ch c√†i ƒë·∫∑t
    - Link download ph·∫ßn m·ªÅm: [https://sourceforge.net/projects/vietocr/](https://sourceforge.net/projects/vietocr/)
    - T·∫£i v·ªÅ v√† c√†i ƒë·∫∑t nh∆∞ b√¨nh th∆∞·ªùng
3. S·ª≠ d·ª•ng
    - M√†n h√¨nh kh·ªüi ƒë·ªông
        
        ![Untitled](Content/Untitled.png)
        
    - N·∫øu OCR 1 file, k√©o th·∫£ file v√†o v√πng l√†m vi·ªác c·ªßa ·ª©ng d·ª•ng v√† ch·ªçn Image‚ÜíOCR all page
        
        ![Result](Content/Untitled%201.png)
        
        Result
        
    - OCR nhi·ªÅu file, ch·ªçn Image‚ÜíBulk OCR, sau ƒë√≥ ƒëi·ªÅn folder input v√† output r·ªìi enter
        
        ![Untitled](Content/Untitled%202.png)
        
        ![K·∫øt qu·∫£ sau khi th·ª≠ nghi·ªám OCR nhi·ªÅu file](Content/Untitled%203.png)
        
        K·∫øt qu·∫£ sau khi th·ª≠ nghi·ªám OCR nhi·ªÅu file
        
    
    ## 2. X·ª≠ l√≠ ng√¥n ng·ªØ t·ª± nhi√™n (NLP)
    
    ## I. Ti·∫øng Anh
    
    1. Th√¥ng tin
        - App: NLTK (Python)
        - Ch·ª©c nƒÉng: Ph√¢n t√≠ch t·ª´ lo·∫°i, lo·∫°i b·ªè stopword.
        - Ng√¥n ng·ªØ h·ªó tr·ª£: Ti·∫øng Anh
    2. C√†i ƒë·∫∑t
        
        ```python
        python -m pip install nltk
        nltk.download()
        ```
        
    3. Source code
        - Testing with model text
            - test.py
            
            ```python
            from nltk.corpus import stopwords
            from nltk.tokenize import word_tokenize
             
            example_sent = """This is a sample sentence,
                              showing off the stop words filtration."""
             
            stop_words = set(stopwords.words('english'))
             
            word_tokens = word_tokenize(example_sent)
             
            filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]
             
            filtered_sentence = []
             
            for w in word_tokens:
                if w not in stop_words:
                    filtered_sentence.append(w)
             
            print(word_tokens)
            print(filtered_sentence)
            ```
            
            ‚Üí Output: 
            
            ```python
            ['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 
            'off', 'the', 'stop', 'words', 'filtration', '.']
            ['This', 'sample', 'sentence', ',', 'showing', 'stop',
            'words', 'filtration', '.']
            ```
            
        - Testing with file txt
            - Source code:
            
            ```python
            import io
            import sys
            from nltk.corpus import stopwords
            from nltk.tokenize import word_tokenize
             
            dir = sys.argv[1]
            
            # word_tokenize accepts
            # a string as an input, not a file.
            stop_words = set(stopwords.words('english'))
            file1 = open(dir)
             
            # Use this to read file content as a stream:
            line = file1.read()
            words = line.split()
            for r in words:
                if not r in stop_words:
                    appendFile = open('filteredtext.txt','a')
                    appendFile.write(" "+r)
                    appendFile.close()
            ```
            
            - Input: python [nlp.py](http://nlp.py) test.txt
            - Output: filteredtext.txt
    
    ## II. Ti·∫øng Vi·ªát
    
    1. Th√¥ng tin
        - App: UndertheseaNLP (Python)
        - Ch·ª©c nƒÉng: Ph√¢n t√≠ch t·ª´ lo·∫°i, lo·∫°i b·ªè stopword.
        - Ng√¥n ng·ªØ h·ªó tr·ª£: Ti·∫øng Vi·ªát
    2. Source Code
        
        ```python
        import io
        import sys
        import os
        import subprocess
        from nltk.corpus import stopwords
        from nltk.tokenize import word_tokenize
        from difflib import SequenceMatcher
        import codecs
        import array as arr
        
        from nltk.corpus import stopwords
        from underthesea import word_tokenize #Use 'underthesea lib' instead of 'nltk' for better result
         
        
        dir = sys.argv[1]
        with io.open(dir,'r',encoding='utf8') as file:
            text = file.read().replace('\n', '')
        text = word_tokenize(text)
        
        stop_words = set(stopwords.words('vietnamese'))
          
        filtered_sentence = [w for w in text if not w.lower() in stop_words]
         
        filtered_sentence = []
         
        for w in text:
            if w not in stop_words:
                filtered_sentence.append(w)
         
        
        print(filtered_sentence)
        
        for r in filtered_sentence:
            with io.open('filteredtext.txt','a',encoding='utf8') as file:
                file.write(r + " ")
                file.close()
        ```
        N·∫øu c√≥ l·ªói x·∫£y ra, vui l√≤ng v√†o ƒë∆∞·ªùng link n√†y ƒë·ªÉ tham kh·∫£o gi·∫£i ph√°p: https://spot-carp-c44.notion.site/Error-No-such-file-419abbee0f914e3cb9e92ac2852856b0

## 3. T√¨m ki·∫øm trong 2000 t·ªáp vƒÉn b·∫£n (ƒê√£ OCR sang file .txt)

## I. Ti·∫øng Anh & Ti·∫øng Vi·ªát

1. Source code
    
    ```python
    import io
    import sys
    import os
    import subprocess
    from nltk.corpus import stopwords
    from nltk.tokenize import word_tokenize
    from difflib import SequenceMatcher
    import codecs
    import array as arr
    
    types_of_encoding = ["utf8", "cp1252"]
    def similar(a,b):
        return SequenceMatcher(None, a, b).ratio()
    dir = sys.argv[1]
    dir2 = sys.argv[2]
    
    with io.open(dir,'r',encoding='utf8') as file:
        data = file.read().replace('\n', '')
    
    # get file ketqua.txt
    # os.chdir(dir2)
    os.system('dir /b /a-d '+ dir2+ " > 5e95d803.tmp")
    #dir folder 
    fo = open("5e95d803.tmp", "r")
    tmps = []
    with open ("5e95d803.tmp") as textFile:
        for line in textFile:
            tmp = line.strip()
            tmps.append(tmp)
    #get list of file to tmps array
    fo.close()
    os.remove("5e95d803.tmp")
    os.chdir(dir2)
    ratiocalc = 0
    ratioMAX = 0
    i = 0
    ratioarray = []
    name = []
    for x in tmps:
        with io.open(x,'r',encoding='utf8') as file199111:
            dataclone = file199111.read().replace('\n', '')
            tmp1234 = similar (data, dataclone) 
            ratioarray.append(tmp1234)
            name.append(x)
    
    #so s√°nh
    for j in range(len(ratioarray)):
        #initially swapped is false
        swapped = False
        i = 0
        while i<len(ratioarray)-1:
            #comparing the adjacent elements
            if ratioarray[i]<ratioarray[i+1]:
                #swapping
                name[i],name[i+1] = name[i+1],name[i]
                ratioarray[i],ratioarray[i+1] = ratioarray[i+1],ratioarray[i]
                
                #Changing the value of swapped
                swapped = True
            i = i+1
        #if swapped is false then the list is sorted
        #we can stop the loop
        if swapped == False:
            break
    
    unique_l = sorted(set(name), key=name.index)
    
    print ("Files that are most similar to the given content")
    for i in range(len(unique_l)):
        print (unique_l[i])
        if i == 4:
            break
    ```
    
2. Example
    
    INPUT: 
    
    ```bash
    python NLP_Search_Files_ENG.py filteredtext.txt ocr_results
    ```
    
    <aside>
    üí° Note: 
    - NLP_Search_ENG.py: python file
    - filteredtext.txt: text file after remove stopwords
    - ocrresults\ : folder txt to search in this
    
    </aside>
    
    OUTPUT:
    
    ```bash
    Files that are most similar to the given content
    [1]Harry Potter and the Philosopher-s Stone_Page_013.jpg.txt
    [1]Harry Potter and the Philosopher-s Stone_Page_215.jpg.txt
    [1]Harry Potter and the Philosopher-s Stone_Page_008.jpg.txt
    [1]Harry Potter and the Philosopher-s Stone_Page_143.jpg.txt
    [1]Harry Potter and the Philosopher-s Stone_Page_214.jpg.txt
    ```
    

## 4. T√¨m ki·∫øm t√†i li·ªáu c√≥ n·ªôi dung t∆∞∆°ng t·ª± tr√™n Internet

## Ti·∫øng Anh v√† Ti·∫øng Vi·ªát

1. Th√¥ng tin
    - App: Magic_Google (Github)
    - Ch·ª©c nƒÉng: Tr√≠ch xu·∫•t n·ªôi dung t·ª´ file txt v√† t√¨m ki·∫øm n·ªôi dung ƒë√≥ tr√™n Internet
2. Source code
    
    ```python
    import io
    import sys
    from magic_google import MagicGoogle
    import pprint
    import io
    import sys
    import os
    import subprocess
    from nltk.corpus import stopwords
    from nltk.tokenize import word_tokenize
    from difflib import SequenceMatcher
    import codecs
    import array as arr
    types_of_encoding = ["utf8", "cp1252"]
    def similar(a,b):
        return SequenceMatcher(None, a, b).ratio()
    dir = sys.argv[1]
    
    with open(dir, 'r') as file:
        data = file.read().replace('\n', '')
    
    PROXIES = []
    
    mg = MagicGoogle(PROXIES)
    
    for url in mg.search_url(query=data):
        pprint.pprint(url)
        ####################################################################
    ```
    
    # *TR√çCH D·∫™N - THAM KH·∫¢O*
    
    - [VietOCR.NET](http://vietocr.sourceforge.net/) is a .NET WPF GUI frontend for [Tesseract OCR engine](https://github.com/tesseract-ocr).
        - Link: [https://sourceforge.net/projects/vietocr/](https://sourceforge.net/projects/vietocr/)
    - V√† c√°c th∆∞ vi·ªán Python kh√°c
    
    # *L·ªúI C·∫¢M ∆†N*
    
    Ch√∫ng em xin c·∫£m ∆°n th·∫ßy V√µ Ho√†ng Qu√¢n - gi·∫£ng vi√™n m√¥n Gi·ªõi thi·ªáu Tr√≠ tu·ªá nh√¢n t·∫°o tr∆∞·ªùng ƒêH KHTN v√† t·∫•t c·∫£ m·ªçi ng∆∞·ªùi ƒë√£ tham gia x√¢y d·ª±ng v√† ph√°t tri·ªÉn ƒë·ªì √°n. Trong qu√° tr√¨nh l√†m, ch√∫ng em kh√¥ng th·ªÉ tr√°nh kh·ªèi m·ªôt v√†i thi·∫øu s√≥t, r·∫•t mong nh·∫≠n ƒë∆∞·ª£c g√≥p √Ω, ƒë√°nh gi√° c·ªßa c√°c th·∫ßy ƒë·ªÉ ho√†n thi·ªán h∆°n.
    
    Xin ch√¢n th√†nh c·∫£m ∆°n!
